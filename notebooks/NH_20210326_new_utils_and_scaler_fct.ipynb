{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NH_20210326_new_utils_and_scaler_fct.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Mv8aAIa0HcMf"},"source":["# Import Packages"]},{"cell_type":"code","metadata":{"id":"N4YWwxNTHbi2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616764920175,"user_tz":-60,"elapsed":8039,"user":{"displayName":"Niklas HÃ¼bel","photoUrl":"","userId":"17667331810374229520"}},"outputId":"29a2d090-9d46-4c42-fabe-c6d73581c2c6"},"source":["import sys\n","import os\n","import shutil\n","import librosa\n","import glob\n","import tqdm\n","import json\n","import ast\n","import random\n","\n","from librosa import display as ld\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import models, layers\n","from tensorflow.keras import backend as K\n","\n","!pip install git+https://github.com/AI-Guru/ngdlm.git\n","tf.compat.v1.disable_eager_execution()\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.externals.joblib import load, dump\n","from sklearn import metrics\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","\n","from IPython import display as ipd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import joblib\n","from configparser import ConfigParser"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/AI-Guru/ngdlm.git\n","  Cloning https://github.com/AI-Guru/ngdlm.git to /tmp/pip-req-build-9om7ay7v\n","  Running command git clone -q https://github.com/AI-Guru/ngdlm.git /tmp/pip-req-build-9om7ay7v\n","Requirement already satisfied (use --upgrade to upgrade): ngdlm==0.0.3 from git+https://github.com/AI-Guru/ngdlm.git in /usr/local/lib/python3.7/dist-packages\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from ngdlm==0.0.3) (2.4.3)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from ngdlm==0.0.3) (2.4.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from ngdlm==0.0.3) (3.2.2)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->ngdlm==0.0.3) (1.4.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->ngdlm==0.0.3) (1.19.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->ngdlm==0.0.3) (3.13)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->ngdlm==0.0.3) (2.10.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (1.12)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (3.3.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (1.6.3)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (0.10.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (1.1.2)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (3.7.4.3)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (1.1.0)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (2.4.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (3.12.4)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (0.2.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (0.3.3)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (2.4.1)\n","Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (1.32.0)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (1.15.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (0.36.2)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (1.12.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ngdlm==0.0.3) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ngdlm==0.0.3) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ngdlm==0.0.3) (1.3.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ngdlm==0.0.3) (2.8.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow->ngdlm==0.0.3) (54.1.2)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (1.27.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (2.23.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (1.8.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (0.4.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (3.3.4)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (4.2.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (0.2.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (2020.12.5)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (3.7.2)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (3.4.1)\n","Building wheels for collected packages: ngdlm\n","  Building wheel for ngdlm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ngdlm: filename=ngdlm-0.0.3-py2.py3-none-any.whl size=32027 sha256=2c87a87b36bf90da279551b874a51b9431e4cae7f04a9c1de9c2c6d926c0bc0a\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-u17w0e7z/wheels/93/06/27/e156acb49f475c364c3c9fa4ad4ab7bfa38808bff5bf9c4647\n","Successfully built ngdlm\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n","  warnings.warn(msg, category=FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"9fTJnTN9Hte0"},"source":["# Mount Google Drive\n","#### 1. First mount"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0qhTQeB2upJN","executionInfo":{"status":"ok","timestamp":1616764924494,"user_tz":-60,"elapsed":770,"user":{"displayName":"Niklas HÃ¼bel","photoUrl":"","userId":"17667331810374229520"}},"outputId":"d8eb617b-6ebf-4083-b4d5-ae526fd3e086"},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/MyDrive/sound-of-failure"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n","/gdrive/MyDrive/sound-of-failure\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rrWBR69_IGJj"},"source":["# Import Own Modules"]},{"cell_type":"code","metadata":{"id":"Xo7kKPNOIMz-","executionInfo":{"status":"ok","timestamp":1616764928035,"user_tz":-60,"elapsed":839,"user":{"displayName":"Niklas HÃ¼bel","photoUrl":"","userId":"17667331810374229520"}}},"source":["sys.path += ['src/01_data_processing', 'src/02_modelling', 'src/00_utils']\n","\n","import spectrogram as spec\n","import train_test_split as splt\n","import train_model_autoencoder as train\n","import naming"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nlIUwYBnSuOd"},"source":["# Global constants"]},{"cell_type":"markdown","metadata":{"id":"PM7yY9Hte7AG"},"source":["### First run the scripts for building the config files.\n","\n","Some of the parameters can be passed through the command line.\n","At present the command line parameters are the following :\n","\n","1. conf_base.py : Script for building the base config file (saves in sound-of-failure/conf/conf_base.ini)\n","        -raw : Pass the location of the raw data dir\n","\n","\n","2. conf_convAE.py : Script for building the config file holding the parameters for Mel Spectrogram and Convolutional Autoencoder (saves in sound-of-failure/conf/make_conf_convAE.ini). Convolutional Autoencoders can be either Autoencoders or Variational Autoencoders.\n","        -ae : AE or VAE\n","        -mel : No. of mels\n","        -fft : No. of FFT bands\n","        -hop : Hop length for the sliding window while calculating FFT\n","        -dim : Time dimension of one spectrogram block after chunking the whole spectrogram\n","        -s : Step for the sliding window for creating chunks from one spectrogram\n"]},{"cell_type":"markdown","metadata":{"id":"HPc6UkH2tZQX"},"source":["To check the description of the command line parameters one could activate the '-h' flag. For example :"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QQkcCK8Ct3Lm","executionInfo":{"status":"ok","timestamp":1616416572156,"user_tz":-60,"elapsed":721,"user":{"displayName":"Niklas HÃ¼bel","photoUrl":"","userId":"17667331810374229520"}},"outputId":"3c4d1422-9891-460c-df83-90cbb579c91d"},"source":["%run /gdrive/MyDrive/sound-of-failure/src/00_utils/make_conf_convAE.py -h"],"execution_count":null,"outputs":[{"output_type":"stream","text":["usage: make_conf_convAE.py [-h] [-ae] [-mel] [-fft] [-hop] [-dim] [-s]\n","\n","Params for Spectrogram and Autoencoder (AE or VAE)\n","\n","optional arguments:\n","  -h, --help            show this help message and exit\n","  -ae , --ae            Type of Autoencoder (AE or VAE)\n","  -mel , --n_mels       No. of mel bands\n","  -fft , --n_fft        No. of FFT bands\n","  -hop , --hop_length   Hop length for FFT calc\n","  -dim , --dim          Time dimension of Spectrogram block\n","  -s , --step           Sliding window step for Spectrogram chunking\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gVxSOVRS0x-_"},"source":["#### Note the change here : While running VAE we have to specify -ae to VAE in the command line. This ensures that the right config file is created (conf/conf_VAE.ini)."]},{"cell_type":"code","metadata":{"id":"A3Id9ote4biL","executionInfo":{"status":"ok","timestamp":1616764474621,"user_tz":-60,"elapsed":1013,"user":{"displayName":"Niklas HÃ¼bel","photoUrl":"","userId":"17667331810374229520"}}},"source":["%run /gdrive/MyDrive/sound-of-failure/src/00_utils/make_conf_base.py -raw '/gdrive/MyDrive/mimii_baseline/dataset' -prj '/gdrive/MyDrive'\n","%run /gdrive/MyDrive/sound-of-failure/src/00_utils/make_conf_convAE.py -prj '/gdrive/MyDrive' -ae VAE -mel 16 -fft 1024 -hop 512 -dim 32 -s 8"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gNT43QWpf7Zo"},"source":["### Then read from the config files\n","\n","There are two config files : \n","\n","1. sound-of-failure/conf/**conf_base**.ini\n","2. sound-of-failure/conf/**conf_VAE**.ini"]},{"cell_type":"markdown","metadata":{"id":"HQUoVWzg0a2-"},"source":["##### Note the change here : In normal Autoencoders the created config file is called conf_convAE.ini. Now is is called conf_VAE.ini."]},{"cell_type":"code","metadata":{"id":"ygPws2kf-gMS","executionInfo":{"status":"ok","timestamp":1616764933574,"user_tz":-60,"elapsed":484,"user":{"displayName":"Niklas HÃ¼bel","photoUrl":"","userId":"17667331810374229520"}}},"source":["base_conf = train.read_config('/gdrive/MyDrive/sound-of-failure/conf/conf_base.ini')\n","param_conf = train.read_config('/gdrive/MyDrive/sound-of-failure/conf/conf_VAE.ini')"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XhqKBfNNhzDG"},"source":["#### Read the parameters directly from the config files\n","\n","Question : Should the reading of config files be done within notebooks or the source script should directly read from them?"]},{"cell_type":"code","metadata":{"id":"1YtgVox0-7b3","executionInfo":{"status":"ok","timestamp":1616764937280,"user_tz":-60,"elapsed":523,"user":{"displayName":"Niklas HÃ¼bel","photoUrl":"","userId":"17667331810374229520"}}},"source":["# Directories\n","RAW_DATA_DIR = base_conf['directories']['raw_data_dir']\n","BASE_DIR = base_conf['directories']['base_dir']\n","\n","\n","# Mel spectrograms\n","N_MELS = param_conf.getint('melspec', 'n_mels')\n","N_FFT = param_conf.getint('melspec', 'n_fft')\n","HOP_LENGTH = param_conf.getint('melspec', 'hop_length')\n","POWER = param_conf.getfloat('melspec', 'power')\n","WINDOW = param_conf.get('melspec', 'window')\n","\n","\n","# Subsampling\n","DIM = param_conf.getint('melspec', 'dim')\n","STEP = param_conf.getint('melspec', 'step')\n","\n","\n","# Scaler and cost function\n","SCALER_TYPE = param_conf.get('model', 'scaler')\n","LOSS = param_conf.get('model', 'loss')\n","\n","\n","# Optimizer\n","OPTIMIZER = param_conf.get('model', 'optimizer')\n","EPOCHS = param_conf.getint('model', 'epochs')\n","BATCH_SIZE = param_conf.getint('model', 'batch_size')\n","VALIDATION_SPLIT = param_conf.getfloat('model', 'val_split')\n","SHUFFLE = param_conf.getboolean('model', 'shuffle')\n","\n","\n","# Autoencoder\n","INPUT_SHAPE = (param_conf.getint('melspec', 'dim'),\n","               param_conf.getint('melspec', 'n_mels'),\n","               1)\n","\n","LATENT_DIM = param_conf.getint('autoencoder', 'latentdim')\n","NUM_NODES = json.loads(param_conf.get('autoencoder', 'num_nodes'))\n","NUM_KERNEL = json.loads(param_conf.get('autoencoder', 'num_kernel'))\n","NUM_STRIDES = param_conf.get('autoencoder', 'num_strides')\n","NUM_STRIDES = list(ast.literal_eval(NUM_STRIDES))\n","\n","\n","# Data\n","DB = param_conf.get('data', 'noise')\n","MACHINE_TYPE = param_conf.get('data', 'machine')\n","MACHINE_ID = param_conf.get('data', 'machine_id')"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PYa7wLT4uQWw"},"source":["# Demo of new naming convention"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dWKRPMNgXJjo","executionInfo":{"status":"ok","timestamp":1616765186627,"user_tz":-60,"elapsed":408,"user":{"displayName":"Niklas HÃ¼bel","photoUrl":"","userId":"17667331810374229520"}},"outputId":"d959d0aa-a471-401e-937d-adad6569153e"},"source":["MODEL_NAME = 'VAE'\n","\n","print(f'Default name string: {naming.get_default_name_string(MODEL_NAME, DB, MACHINE_TYPE, MACHINE_ID)}')\n","print(f'New name string: {naming.get_new_name_string(MODEL_NAME, DB, MACHINE_TYPE, MACHINE_ID)}\\n')\n","\n","name_string = naming.get_default_name_string(MODEL_NAME, DB, MACHINE_TYPE, MACHINE_ID)\n","\n","print(f'Scaler path: {naming.get_scaler_path(name_string)}')\n","print(f'Config path: {naming.get_conf_path(name_string)}')\n","print(f'Model path: {naming.get_model_path(name_string)}')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Default name string: VAE_6dB_valve_id_00\n","New name string: VAE_6dB_valve_id_00\n","\n","Scaler path: models/VAE_6dB_valve_id_00.gz\n","Config path: conf/VAE_6dB_valve_id_00.ini\n","Model path: models/VAE_6dB_valve_id_00.hdf5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nNCFbJV8SAX1"},"source":["# Execute preprocessing steps\n","#### 1. Generate unscaled mel spectrograms (~ 5 minutes)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dc0KZB_h9nwL","executionInfo":{"status":"ok","timestamp":1616764578588,"user_tz":-60,"elapsed":32732,"user":{"displayName":"Niklas HÃ¼bel","photoUrl":"","userId":"17667331810374229520"}},"outputId":"35207b49-db06-4477-8853-f983008ac947"},"source":["spec.make_mel_dirs(BASE_DIR, DB, MACHINE_TYPE, MACHINE_ID)\n","\n","spec.make_mels(RAW_DATA_DIR, BASE_DIR, \n","               DB, MACHINE_TYPE, MACHINE_ID, \n","               N_MELS, N_FFT, HOP_LENGTH, POWER, WINDOW, overwrite=False)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Directory already exists: /gdrive/MyDrive/sound-of-failure/data/mel_spectrograms/6dB/valve/id_00/normal\n","Directory already exists: /gdrive/MyDrive/sound-of-failure/data/mel_spectrograms/6dB/valve/id_00/abnormal\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/991 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Generate normal spectrograms and save to /gdrive/MyDrive/sound-of-failure/data/mel_spectrograms/6dB/valve/id_00/normal.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|ââââââââââ| 991/991 [00:11<00:00, 89.18it/s]\n","  0%|          | 0/119 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Created 0 new spectrograms, kept 991 existing spectrograms.\n","Generate abnormal spectrograms and save to /gdrive/MyDrive/sound-of-failure/data/mel_spectrograms/6dB/valve/id_00/abnormal.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|ââââââââââ| 119/119 [00:01<00:00, 77.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["Created 0 new spectrograms, kept 119 existing spectrograms.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"9cFvil9_SMTt"},"source":["#### 2. Separate train and test files"]},{"cell_type":"code","metadata":{"id":"77iQhf4K9n33","executionInfo":{"status":"ok","timestamp":1616765198507,"user_tz":-60,"elapsed":466,"user":{"displayName":"Niklas HÃ¼bel","photoUrl":"","userId":"17667331810374229520"}}},"source":["train_files, train_labels, test_files, test_labels = splt.make_train_test_split(BASE_DIR, \n","                                                                                DB, MACHINE_TYPE, MACHINE_ID, \n","                                                                                random_seed=1)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k4fNXtLsug8F"},"source":["#### 3. Scaling"]},{"cell_type":"code","metadata":{"id":"BKYV7VkUuor-","executionInfo":{"status":"ok","timestamp":1616765441616,"user_tz":-60,"elapsed":517,"user":{"displayName":"Niklas HÃ¼bel","photoUrl":"","userId":"17667331810374229520"}}},"source":["# Previous, still valid\n","\n","#scaler = spec.create_scaler(SCALER_TYPE)\n","#spec.fit_scaler_to_mel_files(scaler, train_files)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"cXQ_834-9n7y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616765449597,"user_tz":-60,"elapsed":2692,"user":{"displayName":"Niklas HÃ¼bel","photoUrl":"","userId":"17667331810374229520"}},"outputId":"61f64a03-e804-44ba-b3b1-45be3c296df2"},"source":["scaler = spec.fit_and_save_scaler(SCALER_TYPE, train_files, name_string, overwrite=True)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["  5%|â         | 41/872 [00:00<00:02, 404.43it/s]"],"name":"stderr"},{"output_type":"stream","text":["Overwriting existing scaler models/VAE_6dB_valve_id_00.gz.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|ââââââââââ| 872/872 [00:02<00:00, 378.58it/s]"],"name":"stderr"},{"output_type":"stream","text":["Saving scaler to models/VAE_6dB_valve_id_00.gz.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gU5wPZS1t5Zg","executionInfo":{"status":"ok","timestamp":1616765462664,"user_tz":-60,"elapsed":406,"user":{"displayName":"Niklas HÃ¼bel","photoUrl":"","userId":"17667331810374229520"}},"outputId":"fd45d810-db29-44d7-eb59-82a8b25f0916"},"source":["scaler = spec.fit_and_save_scaler(SCALER_TYPE, train_files, name_string, overwrite=False)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Loading existing scaler models/VAE_6dB_valve_id_00.gz.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CoENkjdFuyaf"},"source":[""],"execution_count":null,"outputs":[]}]}