{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NH_20210326_new_utils_and_scaler_fct.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Mv8aAIa0HcMf"},"source":["# Import Packages"]},{"cell_type":"code","metadata":{"id":"N4YWwxNTHbi2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616764920175,"user_tz":-60,"elapsed":8039,"user":{"displayName":"Niklas Hübel","photoUrl":"","userId":"17667331810374229520"}},"outputId":"29a2d090-9d46-4c42-fabe-c6d73581c2c6"},"source":["import sys\n","import os\n","import shutil\n","import librosa\n","import glob\n","import tqdm\n","import json\n","import ast\n","import random\n","\n","from librosa import display as ld\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import models, layers\n","from tensorflow.keras import backend as K\n","\n","!pip install git+https://github.com/AI-Guru/ngdlm.git\n","tf.compat.v1.disable_eager_execution()\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.externals.joblib import load, dump\n","from sklearn import metrics\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","\n","from IPython import display as ipd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import joblib\n","from configparser import ConfigParser"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/AI-Guru/ngdlm.git\n","  Cloning https://github.com/AI-Guru/ngdlm.git to /tmp/pip-req-build-9om7ay7v\n","  Running command git clone -q https://github.com/AI-Guru/ngdlm.git /tmp/pip-req-build-9om7ay7v\n","Requirement already satisfied (use --upgrade to upgrade): ngdlm==0.0.3 from git+https://github.com/AI-Guru/ngdlm.git in /usr/local/lib/python3.7/dist-packages\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from ngdlm==0.0.3) (2.4.3)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from ngdlm==0.0.3) (2.4.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from ngdlm==0.0.3) (3.2.2)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->ngdlm==0.0.3) (1.4.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->ngdlm==0.0.3) (1.19.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->ngdlm==0.0.3) (3.13)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->ngdlm==0.0.3) (2.10.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (1.12)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (3.3.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (1.6.3)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (0.10.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (1.1.2)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (3.7.4.3)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (1.1.0)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (2.4.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (3.12.4)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (0.2.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (0.3.3)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (2.4.1)\n","Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (1.32.0)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (1.15.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (0.36.2)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->ngdlm==0.0.3) (1.12.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ngdlm==0.0.3) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ngdlm==0.0.3) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ngdlm==0.0.3) (1.3.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ngdlm==0.0.3) (2.8.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow->ngdlm==0.0.3) (54.1.2)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (1.27.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (2.23.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (1.8.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (0.4.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (3.3.4)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (4.2.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (0.2.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (2020.12.5)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (3.7.2)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow->ngdlm==0.0.3) (3.4.1)\n","Building wheels for collected packages: ngdlm\n","  Building wheel for ngdlm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ngdlm: filename=ngdlm-0.0.3-py2.py3-none-any.whl size=32027 sha256=2c87a87b36bf90da279551b874a51b9431e4cae7f04a9c1de9c2c6d926c0bc0a\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-u17w0e7z/wheels/93/06/27/e156acb49f475c364c3c9fa4ad4ab7bfa38808bff5bf9c4647\n","Successfully built ngdlm\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n","  warnings.warn(msg, category=FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"9fTJnTN9Hte0"},"source":["# Mount Google Drive\n","#### 1. First mount"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0qhTQeB2upJN","executionInfo":{"status":"ok","timestamp":1616764924494,"user_tz":-60,"elapsed":770,"user":{"displayName":"Niklas Hübel","photoUrl":"","userId":"17667331810374229520"}},"outputId":"d8eb617b-6ebf-4083-b4d5-ae526fd3e086"},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/MyDrive/sound-of-failure"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n","/gdrive/MyDrive/sound-of-failure\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rrWBR69_IGJj"},"source":["# Import Own Modules"]},{"cell_type":"code","metadata":{"id":"Xo7kKPNOIMz-","executionInfo":{"status":"ok","timestamp":1616764928035,"user_tz":-60,"elapsed":839,"user":{"displayName":"Niklas Hübel","photoUrl":"","userId":"17667331810374229520"}}},"source":["sys.path += ['src/01_data_processing', 'src/02_modelling', 'src/00_utils']\n","\n","import spectrogram as spec\n","import train_test_split as splt\n","import train_model_autoencoder as train\n","import naming"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nlIUwYBnSuOd"},"source":["# Global constants"]},{"cell_type":"markdown","metadata":{"id":"PM7yY9Hte7AG"},"source":["### First run the scripts for building the config files.\n","\n","Some of the parameters can be passed through the command line.\n","At present the command line parameters are the following :\n","\n","1. conf_base.py : Script for building the base config file (saves in sound-of-failure/conf/conf_base.ini)\n","        -raw : Pass the location of the raw data dir\n","\n","\n","2. conf_convAE.py : Script for building the config file holding the parameters for Mel Spectrogram and Convolutional Autoencoder (saves in sound-of-failure/conf/make_conf_convAE.ini). Convolutional Autoencoders can be either Autoencoders or Variational Autoencoders.\n","        -ae : AE or VAE\n","        -mel : No. of mels\n","        -fft : No. of FFT bands\n","        -hop : Hop length for the sliding window while calculating FFT\n","        -dim : Time dimension of one spectrogram block after chunking the whole spectrogram\n","        -s : Step for the sliding window for creating chunks from one spectrogram\n"]},{"cell_type":"markdown","metadata":{"id":"HPc6UkH2tZQX"},"source":["To check the description of the command line parameters one could activate the '-h' flag. For example :"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QQkcCK8Ct3Lm","executionInfo":{"status":"ok","timestamp":1616416572156,"user_tz":-60,"elapsed":721,"user":{"displayName":"Niklas Hübel","photoUrl":"","userId":"17667331810374229520"}},"outputId":"3c4d1422-9891-460c-df83-90cbb579c91d"},"source":["%run /gdrive/MyDrive/sound-of-failure/src/00_utils/make_conf_convAE.py -h"],"execution_count":null,"outputs":[{"output_type":"stream","text":["usage: make_conf_convAE.py [-h] [-ae] [-mel] [-fft] [-hop] [-dim] [-s]\n","\n","Params for Spectrogram and Autoencoder (AE or VAE)\n","\n","optional arguments:\n","  -h, --help            show this help message and exit\n","  -ae , --ae            Type of Autoencoder (AE or VAE)\n","  -mel , --n_mels       No. of mel bands\n","  -fft , --n_fft        No. of FFT bands\n","  -hop , --hop_length   Hop length for FFT calc\n","  -dim , --dim          Time dimension of Spectrogram block\n","  -s , --step           Sliding window step for Spectrogram chunking\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gVxSOVRS0x-_"},"source":["#### Note the change here : While running VAE we have to specify -ae to VAE in the command line. This ensures that the right config file is created (conf/conf_VAE.ini)."]},{"cell_type":"code","metadata":{"id":"A3Id9ote4biL","executionInfo":{"status":"ok","timestamp":1616764474621,"user_tz":-60,"elapsed":1013,"user":{"displayName":"Niklas Hübel","photoUrl":"","userId":"17667331810374229520"}}},"source":["%run /gdrive/MyDrive/sound-of-failure/src/00_utils/make_conf_base.py -raw '/gdrive/MyDrive/mimii_baseline/dataset' -prj '/gdrive/MyDrive'\n","%run /gdrive/MyDrive/sound-of-failure/src/00_utils/make_conf_convAE.py -prj '/gdrive/MyDrive' -ae VAE -mel 16 -fft 1024 -hop 512 -dim 32 -s 8"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gNT43QWpf7Zo"},"source":["### Then read from the config files\n","\n","There are two config files : \n","\n","1. sound-of-failure/conf/**conf_base**.ini\n","2. sound-of-failure/conf/**conf_VAE**.ini"]},{"cell_type":"markdown","metadata":{"id":"HQUoVWzg0a2-"},"source":["##### Note the change here : In normal Autoencoders the created config file is called conf_convAE.ini. Now is is called conf_VAE.ini."]},{"cell_type":"code","metadata":{"id":"ygPws2kf-gMS","executionInfo":{"status":"ok","timestamp":1616764933574,"user_tz":-60,"elapsed":484,"user":{"displayName":"Niklas Hübel","photoUrl":"","userId":"17667331810374229520"}}},"source":["base_conf = train.read_config('/gdrive/MyDrive/sound-of-failure/conf/conf_base.ini')\n","param_conf = train.read_config('/gdrive/MyDrive/sound-of-failure/conf/conf_VAE.ini')"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XhqKBfNNhzDG"},"source":["#### Read the parameters directly from the config files\n","\n","Question : Should the reading of config files be done within notebooks or the source script should directly read from them?"]},{"cell_type":"code","metadata":{"id":"1YtgVox0-7b3","executionInfo":{"status":"ok","timestamp":1616764937280,"user_tz":-60,"elapsed":523,"user":{"displayName":"Niklas Hübel","photoUrl":"","userId":"17667331810374229520"}}},"source":["# Directories\n","RAW_DATA_DIR = base_conf['directories']['raw_data_dir']\n","BASE_DIR = base_conf['directories']['base_dir']\n","\n","\n","# Mel spectrograms\n","N_MELS = param_conf.getint('melspec', 'n_mels')\n","N_FFT = param_conf.getint('melspec', 'n_fft')\n","HOP_LENGTH = param_conf.getint('melspec', 'hop_length')\n","POWER = param_conf.getfloat('melspec', 'power')\n","WINDOW = param_conf.get('melspec', 'window')\n","\n","\n","# Subsampling\n","DIM = param_conf.getint('melspec', 'dim')\n","STEP = param_conf.getint('melspec', 'step')\n","\n","\n","# Scaler and cost function\n","SCALER_TYPE = param_conf.get('model', 'scaler')\n","LOSS = param_conf.get('model', 'loss')\n","\n","\n","# Optimizer\n","OPTIMIZER = param_conf.get('model', 'optimizer')\n","EPOCHS = param_conf.getint('model', 'epochs')\n","BATCH_SIZE = param_conf.getint('model', 'batch_size')\n","VALIDATION_SPLIT = param_conf.getfloat('model', 'val_split')\n","SHUFFLE = param_conf.getboolean('model', 'shuffle')\n","\n","\n","# Autoencoder\n","INPUT_SHAPE = (param_conf.getint('melspec', 'dim'),\n","               param_conf.getint('melspec', 'n_mels'),\n","               1)\n","\n","LATENT_DIM = param_conf.getint('autoencoder', 'latentdim')\n","NUM_NODES = json.loads(param_conf.get('autoencoder', 'num_nodes'))\n","NUM_KERNEL = json.loads(param_conf.get('autoencoder', 'num_kernel'))\n","NUM_STRIDES = param_conf.get('autoencoder', 'num_strides')\n","NUM_STRIDES = list(ast.literal_eval(NUM_STRIDES))\n","\n","\n","# Data\n","DB = param_conf.get('data', 'noise')\n","MACHINE_TYPE = param_conf.get('data', 'machine')\n","MACHINE_ID = param_conf.get('data', 'machine_id')"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PYa7wLT4uQWw"},"source":["# Demo of new naming convention"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dWKRPMNgXJjo","executionInfo":{"status":"ok","timestamp":1616765186627,"user_tz":-60,"elapsed":408,"user":{"displayName":"Niklas Hübel","photoUrl":"","userId":"17667331810374229520"}},"outputId":"d959d0aa-a471-401e-937d-adad6569153e"},"source":["MODEL_NAME = 'VAE'\n","\n","print(f'Default name string: {naming.get_default_name_string(MODEL_NAME, DB, MACHINE_TYPE, MACHINE_ID)}')\n","print(f'New name string: {naming.get_new_name_string(MODEL_NAME, DB, MACHINE_TYPE, MACHINE_ID)}\\n')\n","\n","name_string = naming.get_default_name_string(MODEL_NAME, DB, MACHINE_TYPE, MACHINE_ID)\n","\n","print(f'Scaler path: {naming.get_scaler_path(name_string)}')\n","print(f'Config path: {naming.get_conf_path(name_string)}')\n","print(f'Model path: {naming.get_model_path(name_string)}')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Default name string: VAE_6dB_valve_id_00\n","New name string: VAE_6dB_valve_id_00\n","\n","Scaler path: models/VAE_6dB_valve_id_00.gz\n","Config path: conf/VAE_6dB_valve_id_00.ini\n","Model path: models/VAE_6dB_valve_id_00.hdf5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nNCFbJV8SAX1"},"source":["# Execute preprocessing steps\n","#### 1. Generate unscaled mel spectrograms (~ 5 minutes)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dc0KZB_h9nwL","executionInfo":{"status":"ok","timestamp":1616764578588,"user_tz":-60,"elapsed":32732,"user":{"displayName":"Niklas Hübel","photoUrl":"","userId":"17667331810374229520"}},"outputId":"35207b49-db06-4477-8853-f983008ac947"},"source":["spec.make_mel_dirs(BASE_DIR, DB, MACHINE_TYPE, MACHINE_ID)\n","\n","spec.make_mels(RAW_DATA_DIR, BASE_DIR, \n","               DB, MACHINE_TYPE, MACHINE_ID, \n","               N_MELS, N_FFT, HOP_LENGTH, POWER, WINDOW, overwrite=False)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Directory already exists: /gdrive/MyDrive/sound-of-failure/data/mel_spectrograms/6dB/valve/id_00/normal\n","Directory already exists: /gdrive/MyDrive/sound-of-failure/data/mel_spectrograms/6dB/valve/id_00/abnormal\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/991 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Generate normal spectrograms and save to /gdrive/MyDrive/sound-of-failure/data/mel_spectrograms/6dB/valve/id_00/normal.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 991/991 [00:11<00:00, 89.18it/s]\n","  0%|          | 0/119 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Created 0 new spectrograms, kept 991 existing spectrograms.\n","Generate abnormal spectrograms and save to /gdrive/MyDrive/sound-of-failure/data/mel_spectrograms/6dB/valve/id_00/abnormal.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 119/119 [00:01<00:00, 77.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["Created 0 new spectrograms, kept 119 existing spectrograms.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"9cFvil9_SMTt"},"source":["#### 2. Separate train and test files"]},{"cell_type":"code","metadata":{"id":"77iQhf4K9n33","executionInfo":{"status":"ok","timestamp":1616765198507,"user_tz":-60,"elapsed":466,"user":{"displayName":"Niklas Hübel","photoUrl":"","userId":"17667331810374229520"}}},"source":["train_files, train_labels, test_files, test_labels = splt.make_train_test_split(BASE_DIR, \n","                                                                                DB, MACHINE_TYPE, MACHINE_ID, \n","                                                                                random_seed=1)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k4fNXtLsug8F"},"source":["#### 3. Scaling"]},{"cell_type":"code","metadata":{"id":"BKYV7VkUuor-","executionInfo":{"status":"ok","timestamp":1616765441616,"user_tz":-60,"elapsed":517,"user":{"displayName":"Niklas Hübel","photoUrl":"","userId":"17667331810374229520"}}},"source":["# Previous, still valid\n","\n","#scaler = spec.create_scaler(SCALER_TYPE)\n","#spec.fit_scaler_to_mel_files(scaler, train_files)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"cXQ_834-9n7y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616765449597,"user_tz":-60,"elapsed":2692,"user":{"displayName":"Niklas Hübel","photoUrl":"","userId":"17667331810374229520"}},"outputId":"61f64a03-e804-44ba-b3b1-45be3c296df2"},"source":["scaler = spec.fit_and_save_scaler(SCALER_TYPE, train_files, name_string, overwrite=True)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["  5%|▍         | 41/872 [00:00<00:02, 404.43it/s]"],"name":"stderr"},{"output_type":"stream","text":["Overwriting existing scaler models/VAE_6dB_valve_id_00.gz.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 872/872 [00:02<00:00, 378.58it/s]"],"name":"stderr"},{"output_type":"stream","text":["Saving scaler to models/VAE_6dB_valve_id_00.gz.\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gU5wPZS1t5Zg","executionInfo":{"status":"ok","timestamp":1616765462664,"user_tz":-60,"elapsed":406,"user":{"displayName":"Niklas Hübel","photoUrl":"","userId":"17667331810374229520"}},"outputId":"fd45d810-db29-44d7-eb59-82a8b25f0916"},"source":["scaler = spec.fit_and_save_scaler(SCALER_TYPE, train_files, name_string, overwrite=False)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Loading existing scaler models/VAE_6dB_valve_id_00.gz.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CoENkjdFuyaf"},"source":[""],"execution_count":null,"outputs":[]}]}